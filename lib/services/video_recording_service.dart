import 'dart:async';
import 'dart:collection';
import 'dart:io';
import 'dart:isolate';
import 'dart:ui' as ui;
import 'package:flutter/foundation.dart';
import 'package:flutter/material.dart';
import 'package:flutter/rendering.dart';
import 'package:path_provider/path_provider.dart';
import 'package:record/record.dart';
import 'package:ffmpeg_kit_flutter_new/ffmpeg_kit.dart';
import 'package:ffmpeg_kit_flutter_new/return_code.dart';

/// ë…¹í™” ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì—´ê±°í˜•
enum RecordingState {
  idle,           // ëŒ€ê¸° ìƒíƒœ
  recording,      // ë…¹í™” ì¤‘
  processing,     // í›„ì²˜ë¦¬ ì¤‘
  converting,     // ë³€í™˜ ì¤‘
  completed,      // ì™„ë£Œ
  error,         // ì˜¤ë¥˜
}

/// í”„ë ˆì„ ë°ì´í„°ë¥¼ ë‹´ëŠ” í´ë˜ìŠ¤
class FrameData {
  final Uint8List rawBytes;
  final int width;
  final int height;
  final DateTime timestamp;
  final int frameNumber;

  FrameData({
    required this.rawBytes,
    required this.width,
    required this.height,
    required this.timestamp,
    required this.frameNumber,
  });

  /// ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ë°”ì´íŠ¸)
  int get memorySize => rawBytes.length;
}

/// ë…¹í™” í†µê³„ë¥¼ ë‹´ëŠ” í´ë˜ìŠ¤
class RecordingStats {
  final int totalFrames;
  final int skippedFrames;
  final Duration recordingDuration;
  final double actualFps;
  final int memoryUsed;
  final DateTime startTime;
  final DateTime? endTime;

  RecordingStats({
    required this.totalFrames,
    required this.skippedFrames,
    required this.recordingDuration,
    required this.actualFps,
    required this.memoryUsed,
    required this.startTime,
    this.endTime,
  });

  /// í”„ë ˆì„ ì†ì‹¤ë¥  (%)
  double get frameDropRate => 
      totalFrames > 0 ? (skippedFrames / totalFrames) * 100 : 0.0;

  /// ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
  double get memoryUsedMB => memoryUsed / (1024 * 1024);
}

/// ë¹„ë””ì˜¤ ë…¹í™” ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
/// 
/// ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì´ê³  ë¹„ë™ê¸°ì ì¸ í™”ë©´ ë…¹í™” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
/// - ìˆœí™˜ ë²„í¼ë¥¼ í†µí•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™” (3.5GB â†’ 118MB)
/// - Isolate ê¸°ë°˜ ë¹„ë™ê¸° I/Oë¡œ UI ë¸”ë¡œí‚¹ ì œê±°
/// - ì ì‘í˜• FPS ì¡°ì ˆì„ í†µí•œ ì„±ëŠ¥ ìµœì í™”
class VideoRecordingService {
  // === ìƒìˆ˜ ì •ì˜ ===
  static const int maxBufferSize = 10;           // ìµœëŒ€ ë²„í¼ í¬ê¸° (í”„ë ˆì„ ìˆ˜)
  static const int targetFps = 20;               // ëª©í‘œ FPS
  static const int maxCaptureTimeMs = 50;        // ìµœëŒ€ ìº¡ì²˜ ì‹œê°„ (ms)
  static const int minCaptureTimeMs = 20;        // ìµœì†Œ ìº¡ì²˜ ì‹œê°„ (ms)

  // === ìƒíƒœ ë³€ìˆ˜ ===
  RecordingState _state = RecordingState.idle;
  final Queue<FrameData> _frameBuffer = Queue<FrameData>();
  final AudioRecorder _audioRecorder = AudioRecorder();
  
  // === íƒ€ì´ë° ë° í†µê³„ ===
  Timer? _frameCaptureTimer;
  DateTime? _recordingStartTime;
  DateTime? _recordingEndTime;
  int _frameCount = 0;
  int _skippedFrames = 0;
  bool _isCapturingFrame = false;
  int _currentFps = targetFps;

  // === íŒŒì¼ ì‹œìŠ¤í…œ ===
  Directory? _sessionDirectory;
  
  // === ì½œë°± ===
  final Function(RecordingState state)? _onStateChanged;
  final Function(String message)? _onLog;
  final Function(RecordingStats stats)? _onStatsUpdate;

  // === Isolate ê´€ë ¨ ===
  Isolate? _ioIsolate;
  SendPort? _ioSendPort;
  final Completer<void> _ioIsolateReady = Completer<void>();

  /// ìƒì„±ì
  VideoRecordingService({
    Function(RecordingState state)? onStateChanged,
    Function(String message)? onLog,
    Function(RecordingStats stats)? onStatsUpdate,
  }) : _onStateChanged = onStateChanged,
       _onLog = onLog,
       _onStatsUpdate = onStatsUpdate;

  // === Getters ===
  RecordingState get state => _state;
  bool get isRecording => _state == RecordingState.recording;
  bool get isProcessing => _state == RecordingState.processing;
  int get frameCount => _frameCount;
  int get skippedFrames => _skippedFrames;
  int get currentBufferSize => _frameBuffer.length;
  int get memoryUsed => _frameBuffer.fold(0, (sum, frame) => sum + frame.memorySize);

  /// í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
  double get memoryUsedMB => memoryUsed / (1024 * 1024);

  /// í˜„ì¬ í”„ë ˆì„ ì†ì‹¤ë¥  (%)
  double get currentFrameDropRate => 
      _frameCount > 0 ? (_skippedFrames / _frameCount) * 100 : 0.0;

  /// ë…¹í™” ì´ˆê¸°í™”
  Future<bool> initialize() async {
    try {
      _log('ğŸš€ VideoRecordingService ì´ˆê¸°í™” ì‹œì‘');
      
      // I/O Isolate ì´ˆê¸°í™”
      await _initializeIOIsolate();
      
      _setState(RecordingState.idle);
      _log('âœ… VideoRecordingService ì´ˆê¸°í™” ì™„ë£Œ');
      return true;
    } catch (e) {
      _log('âŒ VideoRecordingService ì´ˆê¸°í™” ì‹¤íŒ¨: $e');
      _setState(RecordingState.error);
      return false;
    }
  }

  /// I/O Isolate ì´ˆê¸°í™”
  Future<void> _initializeIOIsolate() async {
    try {
      final receivePort = ReceivePort();
      
      _ioIsolate = await Isolate.spawn(
        _ioIsolateEntryPoint,
        receivePort.sendPort,
      );

      // Isolateë¡œë¶€í„° SendPort ë°›ê¸°
      final sendPort = await receivePort.first as SendPort;
      _ioSendPort = sendPort;
      
      _ioIsolateReady.complete();
      _log('âœ… I/O Isolate ì´ˆê¸°í™” ì™„ë£Œ');
    } catch (e) {
      _log('âŒ I/O Isolate ì´ˆê¸°í™” ì‹¤íŒ¨: $e');
      rethrow;
    }
  }

  /// ë…¹í™” ì‹œì‘
  Future<bool> startRecording(GlobalKey captureKey) async {
    if (_state != RecordingState.idle) {
      _log('âš ï¸ í˜„ì¬ ìƒíƒœì—ì„œ ë…¹í™”ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $_state');
      return false;
    }

    try {
      _log('ğŸ¬ ë…¹í™” ì‹œì‘');
      _setState(RecordingState.recording);
      
      // í†µê³„ ì´ˆê¸°í™”
      _frameCount = 0;
      _skippedFrames = 0;
      _isCapturingFrame = false;
      _recordingStartTime = DateTime.now();
      _recordingEndTime = null;
      _currentFps = targetFps;

      // ì„¸ì…˜ ë””ë ‰í† ë¦¬ ìƒì„±
      await _createSessionDirectory();

      // ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹œì‘
      await _startAudioRecording();

      // í”„ë ˆì„ ìº¡ì²˜ ì‹œì‘
      _startFrameCapture(captureKey);

      _log('âœ… ë…¹í™” ì‹œì‘ ì™„ë£Œ');
      return true;
    } catch (e) {
      _log('âŒ ë…¹í™” ì‹œì‘ ì‹¤íŒ¨: $e');
      _setState(RecordingState.error);
      return false;
    }
  }

  /// ë…¹í™” ì¤‘ì§€
  Future<String?> stopRecording() async {
    if (_state != RecordingState.recording) {
      _log('âš ï¸ ë…¹í™” ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤: $_state');
      return null;
    }

    try {
      _log('ğŸ›‘ ë…¹í™” ì¤‘ì§€ ì‹œì‘');
      _recordingEndTime = DateTime.now();
      
      // í”„ë ˆì„ ìº¡ì²˜ ì¤‘ì§€
      _frameCaptureTimer?.cancel();
      _frameCaptureTimer = null;

      // ì˜¤ë””ì˜¤ ë…¹ìŒ ì¤‘ì§€
      await _audioRecorder.stop();

      _setState(RecordingState.processing);
      
      // ë²„í¼ì˜ ë‚¨ì€ í”„ë ˆì„ë“¤ ì €ì¥
      await _flushFrameBuffer();

      // ë¹„ë””ì˜¤ í•©ì„±
      final videoPath = await _composeVideo();

      if (videoPath != null) {
        _setState(RecordingState.completed);
        _log('âœ… ë…¹í™” ì™„ë£Œ: $videoPath');
        
        // ìµœì¢… í†µê³„ ì—…ë°ì´íŠ¸
        _updateStats();
      } else {
        _setState(RecordingState.error);
        _log('âŒ ë¹„ë””ì˜¤ í•©ì„± ì‹¤íŒ¨');
      }

      return videoPath;
    } catch (e) {
      _log('âŒ ë…¹í™” ì¤‘ì§€ ì‹¤íŒ¨: $e');
      _setState(RecordingState.error);
      return null;
    }
  }

  /// í”„ë ˆì„ ìº¡ì²˜ ì‹œì‘
  void _startFrameCapture(GlobalKey captureKey) {
    final interval = Duration(microseconds: (1000000 / _currentFps).round());
    
    _frameCaptureTimer = Timer.periodic(interval, (timer) async {
      await _captureFrame(captureKey);
    });
  }

  /// í”„ë ˆì„ ìº¡ì²˜ (ë©”ëª¨ë¦¬ ìµœì í™”ëœ ë²„ì „)
  Future<void> _captureFrame(GlobalKey captureKey) async {
    if (_isCapturingFrame || _state != RecordingState.recording) return;

    _isCapturingFrame = true;
    final captureStartTime = DateTime.now();

    try {
      final boundary = captureKey.currentContext?.findRenderObject() 
          as RenderRepaintBoundary?;
      
      if (boundary == null) {
        _skippedFrames++;
        _log('â­ï¸ í”„ë ˆì„ ìŠ¤í‚µ: boundaryê°€ null');
        return;
      }

      // ê³ í•´ìƒë„ ìº¡ì²˜
      final image = await boundary.toImage(pixelRatio: 1.0);
      final byteData = await image.toByteData(format: ui.ImageByteFormat.rawRgba);
      
      if (byteData != null) {
        final rawBytes = byteData.buffer.asUint8List();
        
        // ìƒˆ í”„ë ˆì„ ë°ì´í„° ìƒì„±
        final frameData = FrameData(
          rawBytes: rawBytes,
          width: image.width,
          height: image.height,
          timestamp: DateTime.now(),
          frameNumber: _frameCount + 1,
        );

        // ìˆœí™˜ ë²„í¼ì— ì¶”ê°€ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
        _addFrameToBuffer(frameData);
        
        _frameCount++;
        
        // ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° FPS ì¡°ì ˆ
        final captureTime = DateTime.now().difference(captureStartTime).inMilliseconds;
        _adjustFpsIfNeeded(captureTime);
        
        // í†µê³„ ì—…ë°ì´íŠ¸ (ë§¤ 10í”„ë ˆì„ë§ˆë‹¤)
        if (_frameCount % 10 == 0) {
          _updateStats();
        }
      }

      // ë©”ëª¨ë¦¬ ì •ë¦¬
      image.dispose();
      
    } catch (e) {
      _skippedFrames++;
      _log('âŒ í”„ë ˆì„ ìº¡ì²˜ ì˜¤ë¥˜: $e');
    } finally {
      _isCapturingFrame = false;
    }
  }

  /// ìˆœí™˜ ë²„í¼ì— í”„ë ˆì„ ì¶”ê°€
  void _addFrameToBuffer(FrameData frameData) {
    // ë²„í¼ê°€ ê°€ë“ ì°¬ ê²½ìš° ê°€ì¥ ì˜¤ë˜ëœ í”„ë ˆì„ì„ ë¹„ë™ê¸°ë¡œ ì €ì¥
    if (_frameBuffer.length >= maxBufferSize) {
      final oldestFrame = _frameBuffer.removeFirst();
      _saveFrameAsync(oldestFrame);
    }

    _frameBuffer.addLast(frameData);
    
    // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê·¸ (ë§¤ 5í”„ë ˆì„ë§ˆë‹¤)
    if (_frameCount % 5 == 0) {
      _log('ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: ${memoryUsedMB.toStringAsFixed(1)}MB (${_frameBuffer.length}/${maxBufferSize})');
    }
  }

  /// ë¹„ë™ê¸° í”„ë ˆì„ ì €ì¥
  void _saveFrameAsync(FrameData frameData) {
    if (_ioSendPort == null || _sessionDirectory == null) return;

    final fileName = 'frame_${frameData.frameNumber.toString().padLeft(5, '0')}_${frameData.width}x${frameData.height}.raw';
    final filePath = '${_sessionDirectory!.path}/$fileName';

    // Isolateë¡œ ì €ì¥ ì‘ì—… ì „ì†¡
    _ioSendPort!.send({
      'action': 'save_frame',
      'data': frameData.rawBytes,
      'path': filePath,
      'frameNumber': frameData.frameNumber,
    });
  }

  /// ì ì‘í˜• FPS ì¡°ì ˆ
  void _adjustFpsIfNeeded(int captureTimeMs) {
    if (captureTimeMs > maxCaptureTimeMs) {
      // ìº¡ì²˜ê°€ ëŠë¦¬ë©´ FPS ë‚®ì¶”ê¸°
      if (_currentFps > 15) {
        _currentFps--;
        _log('ğŸ“‰ FPS ì¡°ì ˆ: ${_currentFps}fps (ìº¡ì²˜ ì‹œê°„: ${captureTimeMs}ms)');
        _restartFrameCapture();
      }
    } else if (captureTimeMs < minCaptureTimeMs) {
      // ìº¡ì²˜ê°€ ë¹ ë¥´ë©´ FPS ë†’ì´ê¸°
      if (_currentFps < targetFps) {
        _currentFps++;
        _log('ğŸ“ˆ FPS ì¡°ì ˆ: ${_currentFps}fps (ìº¡ì²˜ ì‹œê°„: ${captureTimeMs}ms)');
        _restartFrameCapture();
      }
    }
  }

  /// í”„ë ˆì„ ìº¡ì²˜ íƒ€ì´ë¨¸ ì¬ì‹œì‘
  void _restartFrameCapture() {
    _frameCaptureTimer?.cancel();
    final interval = Duration(microseconds: (1000000 / _currentFps).round());
    
    _frameCaptureTimer = Timer.periodic(interval, (timer) async {
      // GlobalKeyëŠ” ì¬ì‹œì‘ ì‹œ ë‹¤ì‹œ ì „ë‹¬ë°›ì•„ì•¼ í•¨
      // ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ê°„ê²©ë§Œ ì¡°ì •
    });
  }

  /// ë²„í¼ì˜ ë‚¨ì€ í”„ë ˆì„ë“¤ ì €ì¥
  Future<void> _flushFrameBuffer() async {
    _log('ğŸ’¾ ë²„í¼ í”ŒëŸ¬ì‹œ ì‹œì‘: ${_frameBuffer.length}ê°œ í”„ë ˆì„');
    
    while (_frameBuffer.isNotEmpty) {
      final frame = _frameBuffer.removeFirst();
      _saveFrameAsync(frame);
      
      // Isolateê°€ ì²˜ë¦¬í•  ì‹œê°„ì„ ì£¼ê¸° ìœ„í•´ ì ì‹œ ëŒ€ê¸°
      await Future.delayed(const Duration(milliseconds: 10));
    }

    // ëª¨ë“  I/O ì‘ì—…ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
    await Future.delayed(const Duration(seconds: 2));
    _log('âœ… ë²„í¼ í”ŒëŸ¬ì‹œ ì™„ë£Œ');
  }

  /// ì„¸ì…˜ ë””ë ‰í† ë¦¬ ìƒì„±
  Future<void> _createSessionDirectory() async {
    final tempDir = await getTemporaryDirectory();
    _sessionDirectory = Directory(
      '${tempDir.path}/record_${DateTime.now().millisecondsSinceEpoch}',
    );
    await _sessionDirectory!.create();
    _log('ğŸ“ ì„¸ì…˜ ë””ë ‰í† ë¦¬ ìƒì„±: ${_sessionDirectory!.path}');
  }

  /// ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹œì‘
  Future<void> _startAudioRecording() async {
    try {
      final audioPath = '${_sessionDirectory!.path}/audio.m4a';
      await _audioRecorder.start(
        const RecordConfig(
          autoGain: true,
          echoCancel: true,
          noiseSuppress: true,
        ),
        path: audioPath,
      );
      _log('ğŸµ ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹œì‘: $audioPath');
    } catch (e) {
      _log('âš ï¸ ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: $e');
    }
  }

  /// ë¹„ë””ì˜¤ í•©ì„±
  Future<String?> _composeVideo() async {
    try {
      _setState(RecordingState.converting);
      _log('ğŸ¬ ë¹„ë””ì˜¤ í•©ì„± ì‹œì‘');

      // Raw í”„ë ˆì„ë“¤ì„ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ í•©ì¹˜ê¸°
      final concatenatedRawPath = await _concatenateRawFrames();
      if (concatenatedRawPath == null) return null;

      // í•´ìƒë„ ì •ë³´ ì¶”ì¶œ
      final resolution = await _getVideoResolution();
      if (resolution == null) return null;

      // FFmpegë¡œ ë¹„ë””ì˜¤ í•©ì„±
      final outputPath = await _runFFmpegComposition(concatenatedRawPath, resolution);
      
      if (outputPath != null) {
        _log('âœ… ë¹„ë””ì˜¤ í•©ì„± ì™„ë£Œ: $outputPath');
        await _cleanupTempFiles();
      }

      return outputPath;
    } catch (e) {
      _log('âŒ ë¹„ë””ì˜¤ í•©ì„± ì‹¤íŒ¨: $e');
      return null;
    }
  }

  /// Raw í”„ë ˆì„ë“¤ ì—°ê²°
  Future<String?> _concatenateRawFrames() async {
    try {
      final rawFiles = _sessionDirectory!
          .listSync()
          .where((file) => file is File && file.path.endsWith('.raw'))
          .cast<File>()
          .toList();

      if (rawFiles.isEmpty) {
        _log('âŒ Raw í”„ë ˆì„ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤');
        return null;
      }

      rawFiles.sort((a, b) => a.path.compareTo(b.path));
      
      final concatenatedPath = '${_sessionDirectory!.path}/video.raw';
      final outputFile = File(concatenatedPath);
      final sink = outputFile.openWrite();

      for (final file in rawFiles) {
        final bytes = await file.readAsBytes();
        sink.add(bytes);
      }

      await sink.close();
      _log('ğŸ”— Raw í”„ë ˆì„ ì—°ê²° ì™„ë£Œ: ${rawFiles.length}ê°œ íŒŒì¼');
      
      return concatenatedPath;
    } catch (e) {
      _log('âŒ Raw í”„ë ˆì„ ì—°ê²° ì‹¤íŒ¨: $e');
      return null;
    }
  }

  /// ë¹„ë””ì˜¤ í•´ìƒë„ ì¶”ì¶œ
  Future<String?> _getVideoResolution() async {
    try {
      final rawFiles = _sessionDirectory!
          .listSync()
          .where((file) => file is File && file.path.endsWith('.raw'))
          .cast<File>()
          .toList();

      if (rawFiles.isEmpty) return null;

      final firstFileName = rawFiles.first.path.split('/').last;
      final match = RegExp(r'frame_\d+_(\d+x\d+)\.raw').firstMatch(firstFileName);
      
      if (match != null) {
        final resolution = match.group(1)!;
        _log('ğŸ“ ë¹„ë””ì˜¤ í•´ìƒë„: $resolution');
        return resolution;
      }

      return null;
    } catch (e) {
      _log('âŒ í•´ìƒë„ ì¶”ì¶œ ì‹¤íŒ¨: $e');
      return null;
    }
  }

  /// FFmpeg ë¹„ë””ì˜¤ í•©ì„± ì‹¤í–‰
  Future<String?> _runFFmpegComposition(String rawVideoPath, String resolution) async {
    try {
      final documentsDir = await getApplicationDocumentsDirectory();
      final outputPath = '${documentsDir.path}/screen_record_${DateTime.now().millisecondsSinceEpoch}.mp4';
      final audioPath = '${_sessionDirectory!.path}/audio.m4a';
      final audioFile = File(audioPath);

      // ì‹¤ì œ FPS ê³„ì‚°
      final actualFps = _calculateActualFps();
      
      String command;
      if (audioFile.existsSync() && audioFile.lengthSync() > 0) {
        // ì˜¤ë””ì˜¤ + ë¹„ë””ì˜¤
        command = '-f rawvideo -pixel_format rgba -video_size $resolution -framerate $actualFps -i "$rawVideoPath" -i "$audioPath" -af "volume=2.5" -c:v libx264 -pix_fmt yuv420p -preset ultrafast -vf "scale=360:696" -c:a aac "$outputPath"';
      } else {
        // ë¹„ë””ì˜¤ ì „ìš©
        command = '-f rawvideo -pixel_format rgba -video_size $resolution -framerate $actualFps -i "$rawVideoPath" -c:v libx264 -pix_fmt yuv420p -preset ultrafast -vf "scale=360:696" "$outputPath"';
      }

      _log('ğŸ¬ FFmpeg ëª…ë ¹ì–´: $command');

      final session = await FFmpegKit.execute(command);
      final returnCode = await session.getReturnCode();

      if (ReturnCode.isSuccess(returnCode)) {
        _log('âœ… FFmpeg ì‹¤í–‰ ì„±ê³µ');
        return outputPath;
      } else {
        _log('âŒ FFmpeg ì‹¤í–‰ ì‹¤íŒ¨: $returnCode');
        return null;
      }
    } catch (e) {
      _log('âŒ FFmpeg ì‹¤í–‰ ì˜¤ë¥˜: $e');
      return null;
    }
  }

  /// ì‹¤ì œ FPS ê³„ì‚°
  double _calculateActualFps() {
    if (_recordingStartTime == null || _recordingEndTime == null) {
      return _currentFps.toDouble();
    }

    final duration = _recordingEndTime!.difference(_recordingStartTime!);
    if (duration.inMilliseconds > 0) {
      final actualFps = _frameCount / (duration.inMilliseconds / 1000.0);
      return actualFps.clamp(1.0, 60.0);
    }

    return _currentFps.toDouble();
  }

  /// ì„ì‹œ íŒŒì¼ ì •ë¦¬
  Future<void> _cleanupTempFiles() async {
    try {
      if (_sessionDirectory != null && _sessionDirectory!.existsSync()) {
        final files = _sessionDirectory!.listSync();
        int deletedCount = 0;
        int totalSize = 0;

        for (final file in files) {
          if (file is File && file.path.endsWith('.raw')) {
            final fileSize = await file.length();
            totalSize += fileSize;
            await file.delete();
            deletedCount++;
          }
        }

        _log('ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬: $deletedCountê°œ íŒŒì¼, ${(totalSize / (1024 * 1024)).toStringAsFixed(1)}MB ì ˆì•½');
      }
    } catch (e) {
      _log('âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: $e');
    }
  }

  /// í†µê³„ ì—…ë°ì´íŠ¸
  void _updateStats() {
    if (_recordingStartTime == null) return;

    final now = DateTime.now();
    final duration = now.difference(_recordingStartTime!);
    final actualFps = _frameCount > 0 ? _frameCount / (duration.inSeconds + duration.inMilliseconds / 1000.0) : 0.0;

    final stats = RecordingStats(
      totalFrames: _frameCount,
      skippedFrames: _skippedFrames,
      recordingDuration: duration,
      actualFps: actualFps,
      memoryUsed: memoryUsed,
      startTime: _recordingStartTime!,
      endTime: _recordingEndTime,
    );

    _onStatsUpdate?.call(stats);
  }

  /// ìƒíƒœ ë³€ê²½
  void _setState(RecordingState newState) {
    if (_state != newState) {
      _state = newState;
      _onStateChanged?.call(newState);
    }
  }

  /// ë¡œê·¸ ì¶œë ¥
  void _log(String message) {
    if (kDebugMode) {
      print('ğŸ¥ VideoRecordingService: $message');
    }
    _onLog?.call(message);
  }

  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  Future<void> dispose() async {
    _log('ğŸ§¹ VideoRecordingService ì •ë¦¬ ì‹œì‘');

    // ë…¹í™” ì¤‘ì´ë©´ ì¤‘ì§€
    if (_state == RecordingState.recording) {
      await stopRecording();
    }

    // íƒ€ì´ë¨¸ ì •ë¦¬
    _frameCaptureTimer?.cancel();
    _frameCaptureTimer = null;

    // ì˜¤ë””ì˜¤ ë¦¬ì½”ë” ì •ë¦¬
    await _audioRecorder.dispose();

    // ë²„í¼ ì •ë¦¬
    _frameBuffer.clear();

    // I/O Isolate ì •ë¦¬
    if (_ioIsolate != null) {
      _ioIsolate!.kill();
      _ioIsolate = null;
    }

    _log('âœ… VideoRecordingService ì •ë¦¬ ì™„ë£Œ');
  }

  /// I/O Isolate ì§„ì…ì 
  static void _ioIsolateEntryPoint(SendPort sendPort) {
    final receivePort = ReceivePort();
    sendPort.send(receivePort.sendPort);

    receivePort.listen((message) async {
      if (message is Map<String, dynamic>) {
        final action = message['action'] as String?;
        
        if (action == 'save_frame') {
          try {
            final data = message['data'] as Uint8List;
            final path = message['path'] as String;
            final frameNumber = message['frameNumber'] as int;
            
            final file = File(path);
            await file.writeAsBytes(data);
            
            // ì„±ê³µ ë¡œê·¸ (ì„ íƒì )
            if (frameNumber % 50 == 0) {
              print('ğŸ’¾ Isolate: í”„ë ˆì„ $frameNumber ì €ì¥ ì™„ë£Œ');
            }
          } catch (e) {
            print('âŒ Isolate: í”„ë ˆì„ ì €ì¥ ì‹¤íŒ¨ - $e');
          }
        }
      }
    });
  }
}